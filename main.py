{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: yt-dlp in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (2024.11.18)\n",
      "Requirement already satisfied: pydub in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.25.1)\n",
      "Requirement already satisfied: ffmpeg-python in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (0.2.0)\n",
      "Requirement already satisfied: openai-whisper in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (20240930)\n",
      "Requirement already satisfied: gradio in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (5.7.1)\n",
      "Requirement already satisfied: future in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from ffmpeg-python) (1.0.0)\n",
      "Requirement already satisfied: numba in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai-whisper) (0.60.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai-whisper) (1.26.4)\n",
      "Requirement already satisfied: torch in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai-whisper) (2.5.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai-whisper) (4.67.1)\n",
      "Requirement already satisfied: more-itertools in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai-whisper) (10.5.0)\n",
      "Requirement already satisfied: tiktoken in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from openai-whisper) (0.8.0)\n",
      "Requirement already satisfied: aiofiles<24.0,>=22.0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio) (23.2.1)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio) (4.6.2.post1)\n",
      "Requirement already satisfied: fastapi<1.0,>=0.115.2 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio) (0.115.5)\n",
      "Requirement already satisfied: ffmpy in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio) (0.4.0)\n",
      "Requirement already satisfied: gradio-client==1.5.0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio) (1.5.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio) (0.28.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.25.1 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio) (0.26.3)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: orjson~=3.0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio) (3.10.12)\n",
      "Requirement already satisfied: packaging in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio) (23.2)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio) (2.2.3)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio) (10.2.0)\n",
      "Requirement already satisfied: pydantic>=2.0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio) (2.10.2)\n",
      "Requirement already satisfied: python-multipart==0.0.12 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio) (0.0.12)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio) (6.0.2)\n",
      "Requirement already satisfied: ruff>=0.2.2 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio) (0.8.1)\n",
      "Requirement already satisfied: safehttpx<1.0,>=0.1.1 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio) (0.1.6)\n",
      "Requirement already satisfied: semantic-version~=2.0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio) (2.10.0)\n",
      "Requirement already satisfied: starlette<1.0,>=0.40.0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio) (0.41.3)\n",
      "Requirement already satisfied: tomlkit==0.12.0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio) (0.12.0)\n",
      "Requirement already satisfied: typer<1.0,>=0.12 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio) (0.14.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio) (0.32.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio-client==1.5.0->gradio) (2024.10.0)\n",
      "Requirement already satisfied: websockets<13.0,>=10.0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from gradio-client==1.5.0->gradio) (12.0)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from anyio<5.0,>=3.0->gradio) (1.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from httpx>=0.24.1->gradio) (2022.12.7)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from httpx>=0.24.1->gradio) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface-hub>=0.25.1->gradio) (3.16.0)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pydantic>=2.0->gradio) (2.27.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tqdm->openai-whisper) (0.4.4)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from numba->openai-whisper) (0.43.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from tiktoken->openai-whisper) (2024.11.6)\n",
      "Requirement already satisfied: networkx in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch->openai-whisper) (3.4.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from torch->openai-whisper) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.17.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[youtube] Extracting URL: https://www.youtube.com/watch?v=zdmEzqpAG70\n",
      "[youtube] zdmEzqpAG70: Downloading webpage\n",
      "[youtube] zdmEzqpAG70: Downloading ios player API JSON\n",
      "[youtube] zdmEzqpAG70: Downloading mweb player API JSON\n",
      "[youtube] zdmEzqpAG70: Downloading m3u8 information\n",
      "[info] zdmEzqpAG70: Downloading 1 format(s): 18\n",
      "[download] Destination: downloaded_video.mp4\n",
      "[download] 100% of   58.82MiB in 00:00:10 at 5.38MiB/s     \n",
      "Audio has been saved to downloaded_video.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\whisper\\__init__.py:150: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(fp, map_location=device)\n",
      "C:\\Users\\Hp\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\whisper\\transcribe.py:126: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
      "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
      "Detected language: English\n",
      "[00:00.000 --> 00:23.080]  Hi everyone. So, let us start with lecture one of this course where we will be talking\n",
      "[00:23.080 --> 00:28.320]  about a brief and maybe a bit selective partial history of deep learning.\n",
      "[00:28.320 --> 00:34.080]  So, we talk about deep learning. So, most of this material, the early material that is there,\n",
      "[00:34.080 --> 00:40.160]  at least there in these slides, is taken by from this article on deep learning and neural networks\n",
      "[00:40.160 --> 00:46.400]  and overview by Shmi Duber. There might be some errors in my accounting of the history and if they\n",
      "[00:46.400 --> 00:51.360]  are, then I apologize for them and also feel free to contact me if you think certain portions need to\n",
      "[00:51.360 --> 00:56.400]  be corrected or there are more things which have happened and you would like to me to add them.\n",
      "[00:56.720 --> 01:04.080]  So, I first did this history lecture almost like six years back and it was more easier to manage,\n",
      "[01:04.080 --> 01:10.080]  but in the past four or five years, I think there has been a much rapid exclusion then what it\n",
      "[01:10.080 --> 01:14.800]  was earlier. Even at that time there was quite a bit of work happening, but it has exponentially\n",
      "[01:14.800 --> 01:20.240]  grown since then and it is often hard to keep track of different things. So, maybe I have missed\n",
      "[01:20.320 --> 01:26.880]  quite a few things. I understand for example, speech progression speech is not very appropriately\n",
      "[01:26.880 --> 01:32.480]  captured in these slides, but the idea is just to give you an overall flavor from where we are and\n",
      "[01:32.480 --> 01:36.560]  where we have reached and maybe a few things here and there would have been missed, but it should\n",
      "[01:36.560 --> 01:41.920]  still give you a fairly reasonable idea of what are the latest developments and how they have evolved\n",
      "[01:41.920 --> 01:48.720]  over the years. So, with that primer, let me just start. So, as I was trying to say that when we\n",
      "[01:48.720 --> 01:54.880]  talk about deep learning, we are talking about neural networks and at least we hear that keep\n",
      "[01:54.880 --> 01:59.280]  hearing that a lot of inspiration comes from the biological neurons or at least we are also currently\n",
      "[02:01.440 --> 02:06.480]  still striving to try to understand how the brain does things and maybe come up with models of\n",
      "[02:06.480 --> 02:13.760]  that. So, let us start that history from biology actually and we go back quite a bit of quite a\n",
      "[02:13.760 --> 02:21.520]  few years to 150 years in time to around 1871. And this was a time when people are trying to understand\n",
      "[02:21.520 --> 02:29.200]  what does our nervous system look like. Joseph Van Gelak, who was one of the researchers or\n",
      "[02:29.200 --> 02:35.040]  scientists in this field, he came up with this idea that our nervous system is a continuous\n",
      "[02:35.040 --> 02:41.280]  network as opposed to being composed of various discrete cells which are connected to each other.\n",
      "[02:41.360 --> 02:46.720]  And this view of the brain or the nervous system was called the reticular theory.\n",
      "[02:47.840 --> 02:52.800]  And this will be important in our discussions on deep learning as we keep seeing through these\n",
      "[02:52.800 --> 02:58.320]  slides. So, and again, one of the things I want to emphasize through this history is there were\n",
      "[02:58.320 --> 03:02.640]  various discoveries happen not necessarily in deep learning or in computer science, but in different\n",
      "[03:02.640 --> 03:08.400]  fields which have over the years influenced where we are today. So, one of these was again very early\n",
      "[03:08.480 --> 03:16.320]  in the 1870s. The staining technique was developed and it allowed it was a basically a chemical\n",
      "[03:16.320 --> 03:23.040]  reaction which allowed you to examine nervous tissues better. And Camilio Goldie came up with this\n",
      "[03:23.040 --> 03:29.280]  and using that chemical reaction, he analyzed the slice of the nervous tissue and he came up\n",
      "[03:30.000 --> 03:36.000]  with the same conclusion that actually this nervous system is like one continuous network and it's\n",
      "[03:36.000 --> 03:42.080]  not composed of discrete units. So, he was also a proponent of reticular theory and he his\n",
      "[03:42.080 --> 03:47.520]  evidence for that was through the staining technique. But quite interestingly around the same time\n",
      "[03:49.360 --> 03:54.800]  Santiago, I won't pronounce the full name because I can't use the same technique, the staining\n",
      "[03:54.800 --> 04:02.960]  technique which Goldie had come up with. And by making similar observations using the same technique,\n",
      "[04:02.960 --> 04:09.360]  but maybe seeing things a bit differently, he came up with the conclusion around 1888, 1888, 1891\n",
      "[04:09.360 --> 04:16.640]  time frame that no actually the nervous system is made up of discrete individual cells forming a\n",
      "[04:16.640 --> 04:23.040]  network. It's a two different prominent theories at that time. One says that it's a single\n",
      "[04:23.840 --> 04:28.720]  network. The other says that it's a single continuous network. The other says it's a network of\n",
      "[04:28.720 --> 04:33.520]  discrete elements. That means there are many individual components which are connected together.\n",
      "[04:33.520 --> 04:40.720]  And one is the neuron doctrine and the other is the reticular theory. And then around 1891,\n",
      "[04:41.760 --> 04:49.360]  this gentleman, I'll again pronounce the full name, he coined the term neuron. This term was\n",
      "[04:49.360 --> 04:54.480]  coined by him and today when we talk about artificial neurons, the word neuron originally is\n",
      "[04:54.480 --> 04:59.680]  attributed to this gentleman. And he further consolidated the neuron doctrine. That means he found\n",
      "[04:59.680 --> 05:05.520]  for the evidence and consolidated different views and said that indeed it seems that the neuron\n",
      "[05:05.520 --> 05:10.240]  doctrine is the right way of explaining what the nervous system is as opposed to the reticular\n",
      "[05:10.240 --> 05:16.720]  theory. And just trivia here, he was also the person who coined the term chromosome. It's a two\n",
      "[05:16.720 --> 05:23.120]  very important terms that we hear about today, both coined by this gentleman here. Now here's a\n",
      "[05:23.120 --> 05:28.800]  question. There are these competing theories one proposed by Golgi and the one by the other gentleman,\n",
      "[05:29.520 --> 05:36.160]  reticular theory and neuron doctrine. It's now around 1905 when the Nobel Prize in medicine was\n",
      "[05:36.160 --> 05:41.040]  given. Who do you think it went to? The person who propagated the reticular theory or the neuron\n",
      "[05:41.040 --> 05:50.160]  doctrine? Watch your take on that. So I hear various answers but it turns out that both of them\n",
      "[05:50.160 --> 05:58.320]  got it. So by that time again, we have been 1871 to 1906, quite a few years in terms of the way\n",
      "[05:58.320 --> 06:04.080]  research progresses today, at least in deep learning, several generations, 35 years.\n",
      "[06:04.720 --> 06:10.560]  But still there was not any conclusion on these and both these schools of thoughts were in\n",
      "[06:10.560 --> 06:16.320]  existence with their own champions. And given that the Nobel Prize was given to both of them,\n",
      "[06:16.320 --> 06:22.320]  this result in lasting conflicting ideas and between the two groups of scientists who believed in\n",
      "[06:22.320 --> 06:28.480]  this these two different theories, right. And this took quite a bit of time to resolve and not by\n",
      "[06:29.280 --> 06:37.040]  developments in biology, but developments in a very different field. So around 1950s when electron\n",
      "[06:37.120 --> 06:46.080]  microscopy was, uh, uh, became, uh, uh, useful, at that time using the electron microscopy technology,\n",
      "[06:46.080 --> 06:52.560]  it was finally confirmed that the neuron doctrine is the right one. That means that the brain or\n",
      "[06:52.560 --> 06:58.240]  the nervous system has many small cells called neurons and they are all interconnected to each other\n",
      "[06:58.240 --> 07:03.760]  through synapses, right. And this structure where you have neurons and they have connections between\n",
      "[07:04.240 --> 07:09.200]  is what kind of five forms of foundation of modern deep neural networks also, right. It took\n",
      "[07:09.200 --> 07:15.280]  quite a bit of time and progress in different fields to come to this conclusion, which then motivated\n",
      "[07:15.280 --> 07:21.200]  work in deep neural networks or neural networks at that time, which has now evolved to where it has,\n",
      "[07:21.200 --> 07:26.080]  right. So quite a bit of history and quite a bit of developments from different fields which have\n",
      "[07:26.080 --> 07:31.760]  led to this place, right. So now moving on, or in fact there's one more, uh, before we move on,\n",
      "[07:31.760 --> 07:36.880]  right. There's one more thing about the brains which there was a great debate about, which was,\n",
      "[07:36.880 --> 07:42.160]  uh, whether the processing in brain is localized or is it distributed. So what it means by,\n",
      "[07:42.160 --> 07:48.320]  it means that there was one group which felt that if you're talking about speech or vision or any\n",
      "[07:48.320 --> 07:54.000]  specific, uh, uh, activities that the brain is responsible for, they are localized. There are certain\n",
      "[07:54.000 --> 07:58.160]  portions of the brain which are responsible for speech, certain for vision and so on. And there\n",
      "[07:58.160 --> 08:02.480]  was this another group which thought it's distributed. That means different parts of the brain\n",
      "[08:02.480 --> 08:06.880]  connect in different ways to do different activities. It's not that one part is speech in the other\n",
      "[08:06.880 --> 08:12.800]  part, so right. And you can, uh, go back and look at this video. I'll not play it, which is about this\n",
      "[08:12.800 --> 08:18.880]  great, uh, brain debate about localized versus distributed processing. And that again took a while to,\n",
      "[08:19.760 --> 08:23.520]  uh, settle, right. And now this is again important because again in modern deep neural networks,\n",
      "[08:24.320 --> 08:29.360]  believe that it's more distributed different parts, uh, interact with each other to do different\n",
      "[08:29.360 --> 08:33.920]  things. Whereas there's also push for having what is known as localized processing, especially in\n",
      "[08:33.920 --> 08:38.400]  modern multilingual models, we want certain portions of the network to only, uh,\n",
      "[08:38.400 --> 08:43.360]  there are two computations related to a certain language or even now certain inputs, right.\n",
      "[08:43.360 --> 08:47.360]  And the rest of the network may be doing other things and so on, right. So you can just look at this\n",
      "[08:47.360 --> 08:52.240]  uh, video also which is, uh, again another kind of a debate about brains. The first one was whether\n",
      "[08:52.240 --> 08:57.520]  it's single or distributed or disconnected. Now this is more about whether it's localized or\n",
      "[08:57.520 --> 09:02.560]  distributed, right. And both of these are relevant even today in terms of modern deep neural networks,\n",
      "[09:02.560 --> 09:08.400]  right. So from these, uh, biological neurons where the inspiration for neural networks came,\n",
      "[09:08.400 --> 09:13.840]  now let's move to the actual artificial neurons, right. And that's where this, uh, period of time\n",
      "[09:13.840 --> 09:18.400]  that we'll cover, which is called the spring to the winter of AI. And I'll tell you why these two\n",
      "[09:19.120 --> 09:25.200]  seasons have cropped up in our discussion, right. So around 1943, while we were still trying to\n",
      "[09:25.200 --> 09:30.240]  understand, uh, what the brain is and we had in fact, I mean still today trying to understand it,\n",
      "[09:31.920 --> 09:37.040]  mecholic and pits, right, to neuroscientists and logists and, right. And again, people coming from\n",
      "[09:37.040 --> 09:42.000]  different fields who were contributing to this area, right. Of course, at that time computer science\n",
      "[09:42.480 --> 09:48.960]  was not so evolved. It was still a field which was in formation, right. So, uh, uh,\n",
      "[09:50.240 --> 09:57.440]  or just getting formed. So, so these two, uh, one neuroscientists and logists, they proposed a\n",
      "[09:57.440 --> 10:00.640]  simplified model of the neuron. And this is something that we'll do in the course in\n",
      "[10:01.520 --> 10:06.160]  detail in the next lecture itself, where they just said that a neuron, a model of the brain would\n",
      "[10:06.160 --> 10:10.240]  be that if there are multiple inputs coming to it, right. And these could be inputs from a sensory\n",
      "[10:10.240 --> 10:14.720]  organs. And based on that, it takes a decision. And a very simplified model is where all these inputs\n",
      "[10:14.720 --> 10:20.320]  are binary and the decision is also binary. So I take inputs like, uh, is it training outside? Do I\n",
      "[10:20.320 --> 10:26.000]  have money? Do I have time? And if so, maybe I'll go out to watch a movie, right. So that's how the\n",
      "[10:26.000 --> 10:34.320]  decision, uh, making processes model with a very simplified model, right. And then this, again, got\n",
      "[10:34.320 --> 10:42.320]  modified and, uh, this perceptron model was, uh, proposed by Frank Rosenblatt. And this is what\n",
      "[10:42.320 --> 10:46.720]  he had to say about it when he proposed it. And if you look at the diagram, of course, the perceptron\n",
      "[10:46.720 --> 10:51.760]  model is again something that we'll do in detail in the course. Uh, you'll see that it's very similar\n",
      "[10:51.760 --> 10:55.760]  to the earlier diagram except you see some weights here, right. So now these different decision factors\n",
      "[10:55.760 --> 11:04.000]  have some weights. I would give more emphasis to the input about me having money or not as opposed to,\n",
      "[11:04.080 --> 11:07.760]  whether I'm in the mood to go out or not, because if I don't have money, maybe I can't go out and\n",
      "[11:07.760 --> 11:12.640]  really spend anything or doing anything, right. Uh, so that's the basic idea here. And this is what\n",
      "[11:12.640 --> 11:18.880]  he had to say that the perceptron may eventually be able to learn, make decisions and translate\n",
      "[11:18.880 --> 11:23.840]  languages, right. Now, when I read this side, I find something strange about this statement,\n",
      "[11:23.840 --> 11:29.360]  right. Learn, make decisions and translate languages. So what is the oddity here, right? What, what\n",
      "[11:29.360 --> 11:37.040]  seems a bit odd here? Yeah. So the, so the face translate languages. I can understand about\n",
      "[11:37.040 --> 11:41.280]  learning and making decisions because that's generally what we associate the brain with. But why\n",
      "[11:41.280 --> 11:46.080]  is something so specific, which is about translate languages, right. So this, as you can see, this is a\n",
      "[11:46.080 --> 11:51.680]  period, 1957 to 58, which is after the war. And even during the war, right. I mean, there was\n",
      "[11:51.680 --> 11:56.480]  a lot of emphasis on being able to translate messages from enemies which spoke different\n",
      "[11:56.480 --> 12:01.680]  languages, German, Russian, English and so on, right. And so translation was an important problem\n",
      "[12:01.680 --> 12:07.440]  to be solved in that era. And hence, this was said that this will also be able to learn how to\n",
      "[12:07.440 --> 12:14.800]  translate languages. And today, uh, are almost like 70 years later, right. We are still trying to\n",
      "[12:14.800 --> 12:21.040]  solve that problem very recently. Facebook has released a paper on which can do translation between\n",
      "[12:21.120 --> 12:27.120]  40,000 pairs involving 200 languages, but there's still a very long tale of languages where we still\n",
      "[12:27.120 --> 12:32.640]  need to enable translation for. And of course, this is just initial flag planting in the sense that by\n",
      "[12:32.640 --> 12:38.880]  no means are these 40,000 directions, the translations adequate. They're still at various levels of\n",
      "[12:38.880 --> 12:42.800]  quality and much more is desired to make them really useful. So we are still trying to\n",
      "[12:43.680 --> 12:48.720]  solve that problem after so many years, right. Well, the statement was made many years back. And\n",
      "[12:48.720 --> 12:54.240]  the reason I'm saying that is that as has been a characteristic of a machine learning, deep learning,\n",
      "[12:54.240 --> 13:01.840]  a lot of tall claims get made, but it takes time for those claims to realize, right. And that\n",
      "[13:01.840 --> 13:06.160]  often leads to certain dissatisfaction in terms of what we expect these systems to do versus what\n",
      "[13:06.160 --> 13:11.680]  they can do. Off-late, of course, we are making rapid progress where we're trying to meet some of\n",
      "[13:11.680 --> 13:17.440]  these expectations, but still I would say a lot needs, a lot still desire in terms of really\n",
      "[13:17.440 --> 13:26.240]  understanding the way humans do. And this statement, where again, very interesting, this is the\n",
      "[13:26.240 --> 13:32.960]  embryo of an electronic computer that the Navy expects will be able to walk, talk, see, write,\n",
      "[13:32.960 --> 13:38.880]  reproduce itself and be conscious of its existence, right. Even today, 70 years later, this is stuff\n",
      "[13:38.880 --> 13:45.120]  of sci-fi movies, right. There's a stuff of futuristic movies where we see that AI can now become\n",
      "[13:45.120 --> 13:49.920]  conscious, it can reproduce itself, it can take over the world and so on. We are still, it's still a\n",
      "[13:49.920 --> 13:55.600]  subject of sci-fi movies, it's still not something that has happened in reality, right. So,\n",
      "[13:55.600 --> 14:01.040]  and this is an article from Wayback 1950s and 508, even today we see these such similar articles,\n",
      "[14:01.040 --> 14:06.480]  right. So much, not much has changed in terms of the hype that is generally there around AI\n",
      "[14:06.480 --> 14:14.640]  machine learning, deep learning. Then this all was for a single perceptron. And what we know today\n",
      "[14:14.640 --> 14:21.040]  as deep learnings, which is like a multi-layer network of neurons, right. This idea is also not\n",
      "[14:21.520 --> 14:28.880]  new, right. This was their way back in 1965, 1968 by by scientists called Evac Nenko and his group\n",
      "[14:28.880 --> 14:34.160]  who proposed what is looking like a very modern deep neural network, right. So, this idea also\n",
      "[14:34.160 --> 14:39.600]  existed quite back a lot of these ideas have had their generations, right. They were proposed\n",
      "[14:39.600 --> 14:44.480]  initially, maybe the conditions at that time were not so conducive for these ideas, maybe they\n",
      "[14:44.480 --> 14:49.200]  were a bit ahead of their times. And then 30 years back, again, people pick up those ideas and then\n",
      "[14:49.200 --> 14:53.600]  maybe the conditions were right. So, there's again like a repeating theme in this area, right.\n",
      "[14:54.400 --> 14:59.680]  But around the same time, what happened, right, in 1969. So, 1957, when you saw those statements\n",
      "[14:59.680 --> 15:04.720]  being made about perceptron and then New York Times articles and many such similar articles,\n",
      "[15:04.720 --> 15:10.480]  the next 12, 13 years was what I would call as the spring time of AI. It was as a lot of curiosity\n",
      "[15:10.640 --> 15:15.120]  around this area. A lot of government funding available for this, right. At least in the US, a lot of\n",
      "[15:15.120 --> 15:20.160]  the funding was on science and technology was driven by government bodies at that time. And there\n",
      "[15:20.160 --> 15:26.400]  was a lot of interest in making really AI work, given the promise made of what it could do if\n",
      "[15:26.400 --> 15:33.680]  allowed to flourish, right. But then around 1969, in their now famous book, Minsky and Pepper,\n",
      "[15:33.680 --> 15:40.720]  it outlined the limits of what perceptrons could do, right. And what they said in very simple\n",
      "[15:40.720 --> 15:48.880]  terms is that while we are thinking that perceptron can model any real world phenomenon, what that\n",
      "[15:48.880 --> 15:56.400]  means is that suppose I have a complex decision to make, right, which depends on say various inputs.\n",
      "[15:57.200 --> 16:07.280]  And I will just start using some terminology, say Rn, x belongs to Rn, which, sorry, which means\n",
      "[16:07.280 --> 16:13.280]  there are n inputs, right. And you have a function and you want to take a decision. And this function\n",
      "[16:13.280 --> 16:19.360]  is of course complex. I do not know what it is. So, what claims are being made is that if you have\n",
      "[16:19.360 --> 16:26.160]  this relation where you have an x, you have some function which gives you out y, right. And if you\n",
      "[16:26.560 --> 16:39.520]  give me enough instances of this, which means, okay. Yeah, if you give me x1, y1, x2, y2,\n",
      "[16:40.320 --> 16:45.840]  x3, y3, enough input, output pairs of this function, right. So, you have decisions that you have\n",
      "[16:45.840 --> 16:53.200]  taken in the pass for certain inputs. Then I could train a model, right, which could take again an\n",
      "[16:53.200 --> 16:59.360]  input x and give out an output y, which would be very close to the true y that should have been\n",
      "[16:59.360 --> 17:04.640]  there, right. That is the claim that was being made, right. And what, and that's where, I mean,\n",
      "[17:04.640 --> 17:08.800]  translation languages could be one such example. You have an input which is a sentence and you produce\n",
      "[17:08.800 --> 17:13.520]  an output. And what was being claimed is I can make a model which can take an English sentence and\n",
      "[17:13.520 --> 17:18.240]  give you a Russian sentence as output, which would be very close to the true Russian sentence that\n",
      "[17:18.240 --> 17:22.560]  you would expect. So, those are the claims being made, right. Any, you could take a bunch of\n",
      "[17:22.560 --> 17:26.640]  inputs and give the output which would be very close to the human output that you would expect.\n",
      "[17:27.200 --> 17:31.840]  Now, what Minsky and Pepper showed that even for very simple functions, right, where this is not a\n",
      "[17:31.840 --> 17:37.760]  very complex function, but a very simple function like the xr function for two variables, right. Just\n",
      "[17:37.760 --> 17:43.280]  take one, say, a and b as input and you know what the xr function should give an output. The\n",
      "[17:43.280 --> 17:49.120]  perceptron is not capable of learning that also. That means, I cannot come up with a perceptron\n",
      "[17:49.200 --> 17:56.240]  model which takes a and b as input. And if I change a and b from 0, 0, 0, 1, 1, 0, 1, 1, the output\n",
      "[17:56.240 --> 18:01.200]  would be the same as the two table of the xr function. So, that's what they are shown, right.\n",
      "[18:01.200 --> 18:05.680]  And that kind of led to significant disappointment because now you have like like a very simple\n",
      "[18:05.680 --> 18:09.840]  function and you are claiming that a perceptron cannot even solve that. Then how do you expect to\n",
      "[18:09.840 --> 18:15.200]  solve much more complex real world examples like the translation example or complex decision\n",
      "[18:15.360 --> 18:20.880]  making like giving a bunch of parameters about a patient, right, blood sugar level, cholesterol\n",
      "[18:20.880 --> 18:28.320]  and so on and trying to predict the life expectancy or the possibility of a person getting a cardiac\n",
      "[18:29.040 --> 18:32.720]  ailment in the future and so on. And those are much more complex decisions than just a simple\n",
      "[18:32.720 --> 18:37.680]  xr function, right. So, this led to a lot of disappointment. But unfortunately, right. So,\n",
      "[18:39.120 --> 18:43.600]  while this statement is true, right, and it's a classic example that we also used today, I\n",
      "[18:43.680 --> 18:49.760]  also be doing this in the course. Minskyin-Pepert said this only in the context of a single perceptron,\n",
      "[18:49.760 --> 18:54.160]  right. They said that still said that if you have a network of perceptrons, you could solve\n",
      "[18:54.720 --> 19:01.680]  complex functions, right. But somehow this second part that you cannot do this with a single neuron,\n",
      "[19:01.680 --> 19:07.360]  but with a layer of multiple multiple or a multi-layer network of perceptrons. But you can do it with\n",
      "[19:07.360 --> 19:11.520]  a multi-layer network of perceptrons. The second part often got lost and the first part got\n",
      "[19:11.520 --> 19:16.560]  emphasized that here you cannot do this. And that led to a lot of disappointment and following this.\n",
      "[19:16.560 --> 19:20.400]  And of course, I can't say that this was the primary reason, but this and similar\n",
      "[19:22.000 --> 19:27.120]  evidences with started emerging, there's a slight decline in the interest in funding AI\n",
      "[19:27.120 --> 19:33.840]  for almost the next two decades. And this is what we call the winter of AI, where the interest in\n",
      "[19:33.840 --> 19:41.200]  funding large-scale projects in AI started declining. And people started, I would say rationalizing\n",
      "[19:41.200 --> 19:46.640]  their expectations from AI a bit more, right. But that does not mean that work completely stop.\n",
      "[19:46.640 --> 19:52.800]  No one was doing AI, there was still work happening. And small progress was being made in different\n",
      "[19:52.800 --> 20:00.960]  areas, right. In particular, in 1986, as I said, this was the AI winter of connectionism. And for\n",
      "[20:00.960 --> 20:06.240]  some of you are initiated in this, this connection AI and this is symbolic AI. So people were still\n",
      "[20:06.240 --> 20:11.120]  interested in symbolic AI, but lost interest in what is known as connectionist AI. Whereas\n",
      "[20:11.120 --> 20:17.360]  today's AI is largely dominated by connectionist AI. And we want to again try to see if you can come\n",
      "[20:17.360 --> 20:22.640]  up with hybrid models. Because again, today people are realizing that this way of doing AI, the deep\n",
      "[20:22.640 --> 20:27.520]  learning way of AI has its limitations. And we need to start looking at hybrid methods or\n",
      "[20:27.520 --> 20:32.720]  complete different alternatives to really push the frontier a bit more, right. And this during\n",
      "[20:32.800 --> 20:36.640]  this period, which I'm calling the AI winter, not I, it's generally called the AI winter.\n",
      "[20:36.640 --> 20:41.280]  There's also this abandonment of these ideas, which were similar to deep learning, at that time.\n",
      "[20:42.320 --> 20:47.680]  But some work of course continued. And in particular, there was this bad propagation algorithm,\n",
      "[20:47.680 --> 20:52.160]  which all of you would have read about in blogs, various articles that you have read on deep\n",
      "[20:52.160 --> 20:57.200]  learning. This was again, not something which has been discovered in the last 10, 15 years. In\n",
      "[20:57.280 --> 21:02.640]  fact, it was discovered and re-discovered several times throughout 1960s and 70s. And of course,\n",
      "[21:02.640 --> 21:06.240]  there was not the benefit of having internet where if something gets discovered in one part of\n",
      "[21:06.240 --> 21:10.720]  the world, it immediately propagates. So you might not be aware that someone else has discovered it\n",
      "[21:10.720 --> 21:16.640]  and independently discovered this algorithm. That's what was happening at that time. And around 1986,\n",
      "[21:17.600 --> 21:26.320]  Riemelhardt and others, including Jeffrey Hinton, popularized in this in the context of neural networks\n",
      "[21:26.320 --> 21:32.800]  and they showed that this bad propagation algorithm can be used for training neural networks.\n",
      "[21:32.800 --> 21:38.640]  And this was an important breakthrough because even to this day, most modern deep neural networks\n",
      "[21:38.640 --> 21:46.000]  are trained using the bad propagation algorithm. There was another important and interesting\n",
      "[21:46.000 --> 21:52.560]  fact is this bad propagation within it, right? Or at the heart of it, there's also gradient descent,\n",
      "[21:53.280 --> 21:58.720]  which was much older, almost one century, one and a half century before back propagation.\n",
      "[21:59.280 --> 22:06.560]  And this was discovered or proposed by Kashi, and for a very different purpose. He was trying to use\n",
      "[22:06.560 --> 22:12.400]  gradient descent to compute the orbit of heavenly bodies. There's a lot of interest in astronomy\n",
      "[22:12.400 --> 22:17.760]  at that time and he was trying to look at what is the orbit of heavenly bodies. And in that context,\n",
      "[22:17.760 --> 22:24.400]  he had discovered gradient descent. So again, whatever benefits we are enjoying today,\n",
      "[22:24.400 --> 22:30.400]  they come through the work of many great scientists over centuries in different fields. And that's\n",
      "[22:30.400 --> 22:38.320]  where that has helped us reach where we are today, very unexpected ways. So while we were still in\n",
      "[22:38.320 --> 22:45.920]  this winter period, again this 1989, what came up is this universal approximation theorem,\n",
      "[22:45.920 --> 22:49.760]  which is again something that will come up in the course, right? And what this said, again,\n",
      "[22:49.760 --> 22:56.000]  to repeat what I said earlier, that if you have a function which takes certain x as input and gives\n",
      "[22:56.000 --> 23:01.520]  you y. And in real world, you don't know what this f is, right? So in real world, if I want to say,\n",
      "[23:01.600 --> 23:19.200]  what is my decision? In here, well examples, suppose f is the function that I'm using to decide\n",
      "[23:19.200 --> 23:24.800]  how to hire people or how to predict the life expectancy of a person. I don't know what this\n",
      "[23:24.800 --> 23:29.520]  f is and that is not really known. I just know it depends on certain factors, right? But and what I\n",
      "[23:29.520 --> 23:35.040]  have is several examples of these inputs and outputs that I know a person who had a certain\n",
      "[23:35.600 --> 23:40.240]  blood pressure level, cholesterol level and so on sugar level. And then I know how long that\n",
      "[23:40.240 --> 23:46.080]  person lived and so on, right? So I have many such examples. Now what this theorem said is that\n",
      "[23:46.800 --> 23:51.920]  you could come up with a multi-layered network of neurons, right? Not unlike what\n",
      "[23:51.920 --> 23:56.720]  Pappert and Minskia said that a single neuron cannot do it. They said that if you have a multi-layered\n",
      "[23:56.720 --> 24:03.440]  network of neurons, right? Then you could take an x, given many such examples, you could learn a\n",
      "[24:03.440 --> 24:10.960]  model such that now if you feed an x to it, the y that it's predicts would be very close to f of x,\n",
      "[24:10.960 --> 24:15.520]  which is the true value of the y that you would have got if you knew what that function is, right?\n",
      "[24:15.520 --> 24:20.720]  So what it means is that what I'm trying to show in this diagram is this orange curve that you see\n",
      "[24:20.800 --> 24:32.080]  here, right? Okay, some of the pen is behaving a bit strange. Yeah, the orange curve that you see\n",
      "[24:32.080 --> 24:37.520]  here, suppose this is what my actual f is and I don't know that, right? And now I'm trying to\n",
      "[24:37.520 --> 24:43.600]  approximate it and those I'm doing that approximation with the help of these rectangular bars that\n",
      "[24:43.600 --> 24:49.840]  you see, right? And what this was, this theorem said is that if you have a very deep neural network or\n",
      "[24:49.840 --> 24:53.520]  a multi-layered, in fact, it said even if you have a one-layered network with the large number of\n",
      "[24:53.520 --> 24:59.600]  neurons, then you can approximate this very, very well, right? And that's what we want to do. We had\n",
      "[25:02.320 --> 25:14.800]  the two function, which we did not know. All we knew was several instances of x1 and y1 x2 y2.\n",
      "[25:14.800 --> 25:18.960]  What this theorem says is that if you have many such instances, you could come up with a neural\n",
      "[25:18.960 --> 25:25.040]  network, right? And that those rectangular bars are in some sense the output of the neural network\n",
      "[25:25.680 --> 25:32.560]  such that that output would be very close to the real output, right? And the more neurons you add,\n",
      "[25:32.560 --> 25:37.200]  the better your approximation would be. If you had fewer of neurons, your approximation would be poor,\n",
      "[25:37.200 --> 25:42.160]  like you see in this case, but the more neurons you add, it will be better, right? This theorem\n",
      "[25:42.160 --> 25:46.720]  an illustrative proof of it is something that we'll see, but this was a real breakthrough, right?\n",
      "[25:46.720 --> 25:53.680]  Because now it has almost the reverse effect of what we had for the proof by Pepper and Minsky,\n",
      "[25:53.680 --> 25:58.640]  it said that even for simple functions, a single neuron does not work. Now, what this is saying is that\n",
      "[25:59.120 --> 26:05.680]  for any arbitrary complex function, not even Boolean functions, any arbitrary function that you have,\n",
      "[26:05.680 --> 26:10.720]  no longer what the function looks like, you can always come up with a neural network, which will be\n",
      "[26:10.880 --> 26:16.000]  able to approximate that function to any desired degree of precision, right? And that desired degree of\n",
      "[26:16.000 --> 26:20.800]  precision is controlled by the number of neurons that you have. I fewer neurons, my approximation\n",
      "[26:20.800 --> 26:25.120]  would be very bad, but if I keep adding neurons, my approximation would become better and better,\n",
      "[26:25.120 --> 26:32.160]  right? So this is a real breakthrough that was there. And after this, of course, nothing changed,\n",
      "[26:32.160 --> 26:37.520]  right? But for nothing changed much in the sense that people realize, okay, there is a lot of power\n",
      "[26:37.520 --> 26:45.920]  in deep neural networks. But for the next 20 years or so, or maybe 17, 18 years, on the back of\n",
      "[26:45.920 --> 26:50.240]  these two discoveries, one is back propagation, which allows you to train deep neural networks.\n",
      "[26:50.240 --> 26:54.160]  And the other is the universal approximation theorem, which says that there is value in training deep\n",
      "[26:54.160 --> 27:00.320]  neural networks, because then you can approximate arbitrary real world functions. People try to apply\n",
      "[27:00.320 --> 27:05.200]  these ideas, right, to real world problems. But what they notice is that training a multilayer\n",
      "[27:05.200 --> 27:10.720]  network of neurons using back propagation is not very stable. And it often does not lead to\n",
      "[27:10.720 --> 27:15.600]  conversion. So while in theory, you can use back propagation, while in theory, you can approximate\n",
      "[27:15.600 --> 27:19.680]  any function. But in practice, when you're trying to train this really deep neural networks,\n",
      "[27:19.680 --> 27:26.240]  it's not working, right? So in the next few years from 1989 to not few as almost two decades,\n",
      "[27:27.440 --> 27:32.480]  much practical progress did not happen in terms of deep learning, right? People knew these two things,\n",
      "[27:32.480 --> 27:36.640]  but they were not really able to make them work. In most cases, there were of course still a lot of\n",
      "[27:36.640 --> 27:41.360]  progress happened on convolution neural networks, which you will see soon, right? So that's where we were.\n",
      "[27:41.360 --> 27:45.840]  So we started with the spring, where there was a lot of hype and enthusiasm around AI,\n",
      "[27:46.400 --> 27:51.200]  then things collapsed, and then things kind of stabilized. Okay, let's not completely ignore it.\n",
      "[27:51.200 --> 27:55.360]  Let's keep making some progress and see if you can actually use back propagation to train this deep\n",
      "[27:55.360 --> 27:57.360]  neural networks, right?\n",
      "Start: 0.0, End: 23.080000000000002, Text:  Hi everyone. So, let us start with lecture one of this course where we will be talking\n",
      "Start: 23.080000000000002, End: 28.32, Text:  about a brief and maybe a bit selective partial history of deep learning.\n",
      "Start: 28.32, End: 34.08, Text:  So, we talk about deep learning. So, most of this material, the early material that is there,\n",
      "Start: 34.08, End: 40.16, Text:  at least there in these slides, is taken by from this article on deep learning and neural networks\n",
      "Start: 40.16, End: 46.400000000000006, Text:  and overview by Shmi Duber. There might be some errors in my accounting of the history and if they\n",
      "Start: 46.400000000000006, End: 51.36, Text:  are, then I apologize for them and also feel free to contact me if you think certain portions need to\n",
      "Start: 51.36, End: 56.400000000000006, Text:  be corrected or there are more things which have happened and you would like to me to add them.\n",
      "Start: 56.72, End: 64.08, Text:  So, I first did this history lecture almost like six years back and it was more easier to manage,\n",
      "Start: 64.08, End: 70.08, Text:  but in the past four or five years, I think there has been a much rapid exclusion then what it\n",
      "Start: 70.08, End: 74.8, Text:  was earlier. Even at that time there was quite a bit of work happening, but it has exponentially\n",
      "Start: 74.8, End: 80.24, Text:  grown since then and it is often hard to keep track of different things. So, maybe I have missed\n",
      "Start: 80.32, End: 86.88, Text:  quite a few things. I understand for example, speech progression speech is not very appropriately\n",
      "Start: 86.88, End: 92.47999999999999, Text:  captured in these slides, but the idea is just to give you an overall flavor from where we are and\n",
      "Start: 92.47999999999999, End: 96.56, Text:  where we have reached and maybe a few things here and there would have been missed, but it should\n",
      "Start: 96.56, End: 101.91999999999999, Text:  still give you a fairly reasonable idea of what are the latest developments and how they have evolved\n",
      "Start: 101.91999999999999, End: 108.72, Text:  over the years. So, with that primer, let me just start. So, as I was trying to say that when we\n",
      "Start: 108.72, End: 114.88, Text:  talk about deep learning, we are talking about neural networks and at least we hear that keep\n",
      "Start: 114.88, End: 119.28, Text:  hearing that a lot of inspiration comes from the biological neurons or at least we are also currently\n",
      "Start: 121.44, End: 126.48, Text:  still striving to try to understand how the brain does things and maybe come up with models of\n",
      "Start: 126.48, End: 133.76, Text:  that. So, let us start that history from biology actually and we go back quite a bit of quite a\n",
      "Start: 133.76, End: 141.51999999999998, Text:  few years to 150 years in time to around 1871. And this was a time when people are trying to understand\n",
      "Start: 141.51999999999998, End: 149.2, Text:  what does our nervous system look like. Joseph Van Gelak, who was one of the researchers or\n",
      "Start: 149.2, End: 155.04, Text:  scientists in this field, he came up with this idea that our nervous system is a continuous\n",
      "Start: 155.04, End: 161.28, Text:  network as opposed to being composed of various discrete cells which are connected to each other.\n",
      "Start: 161.36, End: 166.72, Text:  And this view of the brain or the nervous system was called the reticular theory.\n",
      "Start: 167.84, End: 172.8, Text:  And this will be important in our discussions on deep learning as we keep seeing through these\n",
      "Start: 172.8, End: 178.32, Text:  slides. So, and again, one of the things I want to emphasize through this history is there were\n",
      "Start: 178.32, End: 182.64, Text:  various discoveries happen not necessarily in deep learning or in computer science, but in different\n",
      "Start: 182.64, End: 188.4, Text:  fields which have over the years influenced where we are today. So, one of these was again very early\n",
      "Start: 188.48000000000002, End: 196.32, Text:  in the 1870s. The staining technique was developed and it allowed it was a basically a chemical\n",
      "Start: 196.32, End: 203.04000000000002, Text:  reaction which allowed you to examine nervous tissues better. And Camilio Goldie came up with this\n",
      "Start: 203.04000000000002, End: 209.28, Text:  and using that chemical reaction, he analyzed the slice of the nervous tissue and he came up\n",
      "Start: 210.0, End: 216.0, Text:  with the same conclusion that actually this nervous system is like one continuous network and it's\n",
      "Start: 216.0, End: 222.08, Text:  not composed of discrete units. So, he was also a proponent of reticular theory and he his\n",
      "Start: 222.08, End: 227.52, Text:  evidence for that was through the staining technique. But quite interestingly around the same time\n",
      "Start: 229.36, End: 234.8, Text:  Santiago, I won't pronounce the full name because I can't use the same technique, the staining\n",
      "Start: 234.8, End: 242.96, Text:  technique which Goldie had come up with. And by making similar observations using the same technique,\n",
      "Start: 242.96, End: 249.36, Text:  but maybe seeing things a bit differently, he came up with the conclusion around 1888, 1888, 1891\n",
      "Start: 249.36, End: 256.64, Text:  time frame that no actually the nervous system is made up of discrete individual cells forming a\n",
      "Start: 256.64, End: 263.04, Text:  network. It's a two different prominent theories at that time. One says that it's a single\n",
      "Start: 263.84000000000003, End: 268.72, Text:  network. The other says that it's a single continuous network. The other says it's a network of\n",
      "Start: 268.72, End: 273.52000000000004, Text:  discrete elements. That means there are many individual components which are connected together.\n",
      "Start: 273.52000000000004, End: 280.72, Text:  And one is the neuron doctrine and the other is the reticular theory. And then around 1891,\n",
      "Start: 281.76000000000005, End: 289.36, Text:  this gentleman, I'll again pronounce the full name, he coined the term neuron. This term was\n",
      "Start: 289.36, End: 294.48, Text:  coined by him and today when we talk about artificial neurons, the word neuron originally is\n",
      "Start: 294.48, End: 299.68, Text:  attributed to this gentleman. And he further consolidated the neuron doctrine. That means he found\n",
      "Start: 299.68, End: 305.52000000000004, Text:  for the evidence and consolidated different views and said that indeed it seems that the neuron\n",
      "Start: 305.52000000000004, End: 310.24, Text:  doctrine is the right way of explaining what the nervous system is as opposed to the reticular\n",
      "Start: 310.24, End: 316.72, Text:  theory. And just trivia here, he was also the person who coined the term chromosome. It's a two\n",
      "Start: 316.72, End: 323.12, Text:  very important terms that we hear about today, both coined by this gentleman here. Now here's a\n",
      "Start: 323.12, End: 328.8, Text:  question. There are these competing theories one proposed by Golgi and the one by the other gentleman,\n",
      "Start: 329.52, End: 336.16, Text:  reticular theory and neuron doctrine. It's now around 1905 when the Nobel Prize in medicine was\n",
      "Start: 336.16, End: 341.04, Text:  given. Who do you think it went to? The person who propagated the reticular theory or the neuron\n",
      "Start: 341.04, End: 350.16, Text:  doctrine? Watch your take on that. So I hear various answers but it turns out that both of them\n",
      "Start: 350.16, End: 358.32000000000005, Text:  got it. So by that time again, we have been 1871 to 1906, quite a few years in terms of the way\n",
      "Start: 358.32000000000005, End: 364.08000000000004, Text:  research progresses today, at least in deep learning, several generations, 35 years.\n",
      "Start: 364.72, End: 370.56, Text:  But still there was not any conclusion on these and both these schools of thoughts were in\n",
      "Start: 370.56, End: 376.32000000000005, Text:  existence with their own champions. And given that the Nobel Prize was given to both of them,\n",
      "Start: 376.32, End: 382.32, Text:  this result in lasting conflicting ideas and between the two groups of scientists who believed in\n",
      "Start: 382.32, End: 388.48, Text:  this these two different theories, right. And this took quite a bit of time to resolve and not by\n",
      "Start: 389.28, End: 397.03999999999996, Text:  developments in biology, but developments in a very different field. So around 1950s when electron\n",
      "Start: 397.12, End: 406.08000000000004, Text:  microscopy was, uh, uh, became, uh, uh, useful, at that time using the electron microscopy technology,\n",
      "Start: 406.08000000000004, End: 412.56, Text:  it was finally confirmed that the neuron doctrine is the right one. That means that the brain or\n",
      "Start: 412.56, End: 418.24, Text:  the nervous system has many small cells called neurons and they are all interconnected to each other\n",
      "Start: 418.24, End: 423.76, Text:  through synapses, right. And this structure where you have neurons and they have connections between\n",
      "Start: 424.24, End: 429.2, Text:  is what kind of five forms of foundation of modern deep neural networks also, right. It took\n",
      "Start: 429.2, End: 435.28, Text:  quite a bit of time and progress in different fields to come to this conclusion, which then motivated\n",
      "Start: 435.28, End: 441.2, Text:  work in deep neural networks or neural networks at that time, which has now evolved to where it has,\n",
      "Start: 441.2, End: 446.08, Text:  right. So quite a bit of history and quite a bit of developments from different fields which have\n",
      "Start: 446.08, End: 451.76, Text:  led to this place, right. So now moving on, or in fact there's one more, uh, before we move on,\n",
      "Start: 451.76, End: 456.88, Text:  right. There's one more thing about the brains which there was a great debate about, which was,\n",
      "Start: 456.88, End: 462.15999999999997, Text:  uh, whether the processing in brain is localized or is it distributed. So what it means by,\n",
      "Start: 462.15999999999997, End: 468.32, Text:  it means that there was one group which felt that if you're talking about speech or vision or any\n",
      "Start: 468.32, End: 474.0, Text:  specific, uh, uh, activities that the brain is responsible for, they are localized. There are certain\n",
      "Start: 474.0, End: 478.15999999999997, Text:  portions of the brain which are responsible for speech, certain for vision and so on. And there\n",
      "Start: 478.16, End: 482.48, Text:  was this another group which thought it's distributed. That means different parts of the brain\n",
      "Start: 482.48, End: 486.88000000000005, Text:  connect in different ways to do different activities. It's not that one part is speech in the other\n",
      "Start: 486.88000000000005, End: 492.8, Text:  part, so right. And you can, uh, go back and look at this video. I'll not play it, which is about this\n",
      "Start: 492.8, End: 498.88, Text:  great, uh, brain debate about localized versus distributed processing. And that again took a while to,\n",
      "Start: 499.76000000000005, End: 503.52000000000004, Text:  uh, settle, right. And now this is again important because again in modern deep neural networks,\n",
      "Start: 504.32, End: 509.35999999999996, Text:  believe that it's more distributed different parts, uh, interact with each other to do different\n",
      "Start: 509.35999999999996, End: 513.92, Text:  things. Whereas there's also push for having what is known as localized processing, especially in\n",
      "Start: 513.92, End: 518.4, Text:  modern multilingual models, we want certain portions of the network to only, uh,\n",
      "Start: 518.4, End: 523.36, Text:  there are two computations related to a certain language or even now certain inputs, right.\n",
      "Start: 523.36, End: 527.36, Text:  And the rest of the network may be doing other things and so on, right. So you can just look at this\n",
      "Start: 527.36, End: 532.24, Text:  uh, video also which is, uh, again another kind of a debate about brains. The first one was whether\n",
      "Start: 532.24, End: 537.52, Text:  it's single or distributed or disconnected. Now this is more about whether it's localized or\n",
      "Start: 537.52, End: 542.5600000000001, Text:  distributed, right. And both of these are relevant even today in terms of modern deep neural networks,\n",
      "Start: 542.5600000000001, End: 548.4, Text:  right. So from these, uh, biological neurons where the inspiration for neural networks came,\n",
      "Start: 548.4, End: 553.84, Text:  now let's move to the actual artificial neurons, right. And that's where this, uh, period of time\n",
      "Start: 553.84, End: 558.4, Text:  that we'll cover, which is called the spring to the winter of AI. And I'll tell you why these two\n",
      "Start: 559.12, End: 565.1999999999999, Text:  seasons have cropped up in our discussion, right. So around 1943, while we were still trying to\n",
      "Start: 565.1999999999999, End: 570.24, Text:  understand, uh, what the brain is and we had in fact, I mean still today trying to understand it,\n",
      "Start: 571.92, End: 577.04, Text:  mecholic and pits, right, to neuroscientists and logists and, right. And again, people coming from\n",
      "Start: 577.04, End: 582.0, Text:  different fields who were contributing to this area, right. Of course, at that time computer science\n",
      "Start: 582.48, End: 588.96, Text:  was not so evolved. It was still a field which was in formation, right. So, uh, uh,\n",
      "Start: 590.24, End: 597.44, Text:  or just getting formed. So, so these two, uh, one neuroscientists and logists, they proposed a\n",
      "Start: 597.44, End: 600.64, Text:  simplified model of the neuron. And this is something that we'll do in the course in\n",
      "Start: 601.52, End: 606.16, Text:  detail in the next lecture itself, where they just said that a neuron, a model of the brain would\n",
      "Start: 606.16, End: 610.24, Text:  be that if there are multiple inputs coming to it, right. And these could be inputs from a sensory\n",
      "Start: 610.24, End: 614.72, Text:  organs. And based on that, it takes a decision. And a very simplified model is where all these inputs\n",
      "Start: 614.72, End: 620.32, Text:  are binary and the decision is also binary. So I take inputs like, uh, is it training outside? Do I\n",
      "Start: 620.32, End: 626.0, Text:  have money? Do I have time? And if so, maybe I'll go out to watch a movie, right. So that's how the\n",
      "Start: 626.0, End: 634.32, Text:  decision, uh, making processes model with a very simplified model, right. And then this, again, got\n",
      "Start: 634.32, End: 642.32, Text:  modified and, uh, this perceptron model was, uh, proposed by Frank Rosenblatt. And this is what\n",
      "Start: 642.32, End: 646.72, Text:  he had to say about it when he proposed it. And if you look at the diagram, of course, the perceptron\n",
      "Start: 646.72, End: 651.7600000000001, Text:  model is again something that we'll do in detail in the course. Uh, you'll see that it's very similar\n",
      "Start: 651.7600000000001, End: 655.7600000000001, Text:  to the earlier diagram except you see some weights here, right. So now these different decision factors\n",
      "Start: 655.7600000000001, End: 664.0, Text:  have some weights. I would give more emphasis to the input about me having money or not as opposed to,\n",
      "Start: 664.08, End: 667.76, Text:  whether I'm in the mood to go out or not, because if I don't have money, maybe I can't go out and\n",
      "Start: 667.76, End: 672.64, Text:  really spend anything or doing anything, right. Uh, so that's the basic idea here. And this is what\n",
      "Start: 672.64, End: 678.88, Text:  he had to say that the perceptron may eventually be able to learn, make decisions and translate\n",
      "Start: 678.88, End: 683.84, Text:  languages, right. Now, when I read this side, I find something strange about this statement,\n",
      "Start: 683.84, End: 689.36, Text:  right. Learn, make decisions and translate languages. So what is the oddity here, right? What, what\n",
      "Start: 689.36, End: 697.04, Text:  seems a bit odd here? Yeah. So the, so the face translate languages. I can understand about\n",
      "Start: 697.04, End: 701.28, Text:  learning and making decisions because that's generally what we associate the brain with. But why\n",
      "Start: 701.28, End: 706.08, Text:  is something so specific, which is about translate languages, right. So this, as you can see, this is a\n",
      "Start: 706.08, End: 711.6800000000001, Text:  period, 1957 to 58, which is after the war. And even during the war, right. I mean, there was\n",
      "Start: 711.6800000000001, End: 716.48, Text:  a lot of emphasis on being able to translate messages from enemies which spoke different\n",
      "Start: 716.48, End: 721.6800000000001, Text:  languages, German, Russian, English and so on, right. And so translation was an important problem\n",
      "Start: 721.6800000000001, End: 727.44, Text:  to be solved in that era. And hence, this was said that this will also be able to learn how to\n",
      "Start: 727.44, End: 734.8000000000001, Text:  translate languages. And today, uh, are almost like 70 years later, right. We are still trying to\n",
      "Start: 734.8000000000001, End: 741.04, Text:  solve that problem very recently. Facebook has released a paper on which can do translation between\n",
      "Start: 741.12, End: 747.12, Text:  40,000 pairs involving 200 languages, but there's still a very long tale of languages where we still\n",
      "Start: 747.12, End: 752.64, Text:  need to enable translation for. And of course, this is just initial flag planting in the sense that by\n",
      "Start: 752.64, End: 758.88, Text:  no means are these 40,000 directions, the translations adequate. They're still at various levels of\n",
      "Start: 758.88, End: 762.8, Text:  quality and much more is desired to make them really useful. So we are still trying to\n",
      "Start: 763.68, End: 768.7199999999999, Text:  solve that problem after so many years, right. Well, the statement was made many years back. And\n",
      "Start: 768.72, End: 774.24, Text:  the reason I'm saying that is that as has been a characteristic of a machine learning, deep learning,\n",
      "Start: 774.24, End: 781.84, Text:  a lot of tall claims get made, but it takes time for those claims to realize, right. And that\n",
      "Start: 781.84, End: 786.1600000000001, Text:  often leads to certain dissatisfaction in terms of what we expect these systems to do versus what\n",
      "Start: 786.1600000000001, End: 791.6800000000001, Text:  they can do. Off-late, of course, we are making rapid progress where we're trying to meet some of\n",
      "Start: 791.6800000000001, End: 797.44, Text:  these expectations, but still I would say a lot needs, a lot still desire in terms of really\n",
      "Start: 797.44, End: 806.24, Text:  understanding the way humans do. And this statement, where again, very interesting, this is the\n",
      "Start: 806.24, End: 812.96, Text:  embryo of an electronic computer that the Navy expects will be able to walk, talk, see, write,\n",
      "Start: 812.96, End: 818.8800000000001, Text:  reproduce itself and be conscious of its existence, right. Even today, 70 years later, this is stuff\n",
      "Start: 818.8800000000001, End: 825.12, Text:  of sci-fi movies, right. There's a stuff of futuristic movies where we see that AI can now become\n",
      "Start: 825.12, End: 829.92, Text:  conscious, it can reproduce itself, it can take over the world and so on. We are still, it's still a\n",
      "Start: 829.92, End: 835.6, Text:  subject of sci-fi movies, it's still not something that has happened in reality, right. So,\n",
      "Start: 835.6, End: 841.04, Text:  and this is an article from Wayback 1950s and 508, even today we see these such similar articles,\n",
      "Start: 841.04, End: 846.48, Text:  right. So much, not much has changed in terms of the hype that is generally there around AI\n",
      "Start: 846.48, End: 854.64, Text:  machine learning, deep learning. Then this all was for a single perceptron. And what we know today\n",
      "Start: 854.64, End: 861.04, Text:  as deep learnings, which is like a multi-layer network of neurons, right. This idea is also not\n",
      "Start: 861.52, End: 868.88, Text:  new, right. This was their way back in 1965, 1968 by by scientists called Evac Nenko and his group\n",
      "Start: 868.88, End: 874.16, Text:  who proposed what is looking like a very modern deep neural network, right. So, this idea also\n",
      "Start: 874.16, End: 879.6, Text:  existed quite back a lot of these ideas have had their generations, right. They were proposed\n",
      "Start: 879.6, End: 884.48, Text:  initially, maybe the conditions at that time were not so conducive for these ideas, maybe they\n",
      "Start: 884.48, End: 889.2, Text:  were a bit ahead of their times. And then 30 years back, again, people pick up those ideas and then\n",
      "Start: 889.2, End: 893.6, Text:  maybe the conditions were right. So, there's again like a repeating theme in this area, right.\n",
      "Start: 894.4, End: 899.6800000000001, Text:  But around the same time, what happened, right, in 1969. So, 1957, when you saw those statements\n",
      "Start: 899.6800000000001, End: 904.72, Text:  being made about perceptron and then New York Times articles and many such similar articles,\n",
      "Start: 904.72, End: 910.48, Text:  the next 12, 13 years was what I would call as the spring time of AI. It was as a lot of curiosity\n",
      "Start: 910.64, End: 915.12, Text:  around this area. A lot of government funding available for this, right. At least in the US, a lot of\n",
      "Start: 915.12, End: 920.16, Text:  the funding was on science and technology was driven by government bodies at that time. And there\n",
      "Start: 920.16, End: 926.4, Text:  was a lot of interest in making really AI work, given the promise made of what it could do if\n",
      "Start: 926.4, End: 933.6800000000001, Text:  allowed to flourish, right. But then around 1969, in their now famous book, Minsky and Pepper,\n",
      "Start: 933.68, End: 940.7199999999999, Text:  it outlined the limits of what perceptrons could do, right. And what they said in very simple\n",
      "Start: 940.7199999999999, End: 948.88, Text:  terms is that while we are thinking that perceptron can model any real world phenomenon, what that\n",
      "Start: 948.88, End: 956.4, Text:  means is that suppose I have a complex decision to make, right, which depends on say various inputs.\n",
      "Start: 957.1999999999999, End: 967.28, Text:  And I will just start using some terminology, say Rn, x belongs to Rn, which, sorry, which means\n",
      "Start: 967.28, End: 973.28, Text:  there are n inputs, right. And you have a function and you want to take a decision. And this function\n",
      "Start: 973.28, End: 979.36, Text:  is of course complex. I do not know what it is. So, what claims are being made is that if you have\n",
      "Start: 979.36, End: 986.16, Text:  this relation where you have an x, you have some function which gives you out y, right. And if you\n",
      "Start: 986.56, End: 999.52, Text:  give me enough instances of this, which means, okay. Yeah, if you give me x1, y1, x2, y2,\n",
      "Start: 1000.3199999999999, End: 1005.8399999999999, Text:  x3, y3, enough input, output pairs of this function, right. So, you have decisions that you have\n",
      "Start: 1005.8399999999999, End: 1013.1999999999999, Text:  taken in the pass for certain inputs. Then I could train a model, right, which could take again an\n",
      "Start: 1013.2, End: 1019.36, Text:  input x and give out an output y, which would be very close to the true y that should have been\n",
      "Start: 1019.36, End: 1024.64, Text:  there, right. That is the claim that was being made, right. And what, and that's where, I mean,\n",
      "Start: 1024.64, End: 1028.8, Text:  translation languages could be one such example. You have an input which is a sentence and you produce\n",
      "Start: 1028.8, End: 1033.52, Text:  an output. And what was being claimed is I can make a model which can take an English sentence and\n",
      "Start: 1033.52, End: 1038.24, Text:  give you a Russian sentence as output, which would be very close to the true Russian sentence that\n",
      "Start: 1038.24, End: 1042.56, Text:  you would expect. So, those are the claims being made, right. Any, you could take a bunch of\n",
      "Start: 1042.56, End: 1046.6399999999999, Text:  inputs and give the output which would be very close to the human output that you would expect.\n",
      "Start: 1047.2, End: 1051.84, Text:  Now, what Minsky and Pepper showed that even for very simple functions, right, where this is not a\n",
      "Start: 1051.84, End: 1057.76, Text:  very complex function, but a very simple function like the xr function for two variables, right. Just\n",
      "Start: 1057.76, End: 1063.28, Text:  take one, say, a and b as input and you know what the xr function should give an output. The\n",
      "Start: 1063.28, End: 1069.12, Text:  perceptron is not capable of learning that also. That means, I cannot come up with a perceptron\n",
      "Start: 1069.1999999999998, End: 1076.2399999999998, Text:  model which takes a and b as input. And if I change a and b from 0, 0, 0, 1, 1, 0, 1, 1, the output\n",
      "Start: 1076.2399999999998, End: 1081.1999999999998, Text:  would be the same as the two table of the xr function. So, that's what they are shown, right.\n",
      "Start: 1081.1999999999998, End: 1085.6799999999998, Text:  And that kind of led to significant disappointment because now you have like like a very simple\n",
      "Start: 1085.6799999999998, End: 1089.84, Text:  function and you are claiming that a perceptron cannot even solve that. Then how do you expect to\n",
      "Start: 1089.84, End: 1095.1999999999998, Text:  solve much more complex real world examples like the translation example or complex decision\n",
      "Start: 1095.3600000000001, End: 1100.88, Text:  making like giving a bunch of parameters about a patient, right, blood sugar level, cholesterol\n",
      "Start: 1100.88, End: 1108.32, Text:  and so on and trying to predict the life expectancy or the possibility of a person getting a cardiac\n",
      "Start: 1109.04, End: 1112.72, Text:  ailment in the future and so on. And those are much more complex decisions than just a simple\n",
      "Start: 1112.72, End: 1117.68, Text:  xr function, right. So, this led to a lot of disappointment. But unfortunately, right. So,\n",
      "Start: 1119.1200000000001, End: 1123.6000000000001, Text:  while this statement is true, right, and it's a classic example that we also used today, I\n",
      "Start: 1123.6799999999998, End: 1129.76, Text:  also be doing this in the course. Minskyin-Pepert said this only in the context of a single perceptron,\n",
      "Start: 1129.76, End: 1134.1599999999999, Text:  right. They said that still said that if you have a network of perceptrons, you could solve\n",
      "Start: 1134.7199999999998, End: 1141.6799999999998, Text:  complex functions, right. But somehow this second part that you cannot do this with a single neuron,\n",
      "Start: 1141.6799999999998, End: 1147.36, Text:  but with a layer of multiple multiple or a multi-layer network of perceptrons. But you can do it with\n",
      "Start: 1147.36, End: 1151.52, Text:  a multi-layer network of perceptrons. The second part often got lost and the first part got\n",
      "Start: 1151.52, End: 1156.56, Text:  emphasized that here you cannot do this. And that led to a lot of disappointment and following this.\n",
      "Start: 1156.56, End: 1160.4, Text:  And of course, I can't say that this was the primary reason, but this and similar\n",
      "Start: 1162.0, End: 1167.12, Text:  evidences with started emerging, there's a slight decline in the interest in funding AI\n",
      "Start: 1167.12, End: 1173.84, Text:  for almost the next two decades. And this is what we call the winter of AI, where the interest in\n",
      "Start: 1173.84, End: 1181.2, Text:  funding large-scale projects in AI started declining. And people started, I would say rationalizing\n",
      "Start: 1181.2, End: 1186.64, Text:  their expectations from AI a bit more, right. But that does not mean that work completely stop.\n",
      "Start: 1186.64, End: 1192.8, Text:  No one was doing AI, there was still work happening. And small progress was being made in different\n",
      "Start: 1192.8, End: 1200.96, Text:  areas, right. In particular, in 1986, as I said, this was the AI winter of connectionism. And for\n",
      "Start: 1200.96, End: 1206.24, Text:  some of you are initiated in this, this connection AI and this is symbolic AI. So people were still\n",
      "Start: 1206.24, End: 1211.1200000000001, Text:  interested in symbolic AI, but lost interest in what is known as connectionist AI. Whereas\n",
      "Start: 1211.1200000000001, End: 1217.36, Text:  today's AI is largely dominated by connectionist AI. And we want to again try to see if you can come\n",
      "Start: 1217.36, End: 1222.64, Text:  up with hybrid models. Because again, today people are realizing that this way of doing AI, the deep\n",
      "Start: 1222.64, End: 1227.52, Text:  learning way of AI has its limitations. And we need to start looking at hybrid methods or\n",
      "Start: 1227.52, End: 1232.72, Text:  complete different alternatives to really push the frontier a bit more, right. And this during\n",
      "Start: 1232.8, End: 1236.64, Text:  this period, which I'm calling the AI winter, not I, it's generally called the AI winter.\n",
      "Start: 1236.64, End: 1241.28, Text:  There's also this abandonment of these ideas, which were similar to deep learning, at that time.\n",
      "Start: 1242.32, End: 1247.68, Text:  But some work of course continued. And in particular, there was this bad propagation algorithm,\n",
      "Start: 1247.68, End: 1252.16, Text:  which all of you would have read about in blogs, various articles that you have read on deep\n",
      "Start: 1252.16, End: 1257.2, Text:  learning. This was again, not something which has been discovered in the last 10, 15 years. In\n",
      "Start: 1257.28, End: 1262.64, Text:  fact, it was discovered and re-discovered several times throughout 1960s and 70s. And of course,\n",
      "Start: 1262.64, End: 1266.24, Text:  there was not the benefit of having internet where if something gets discovered in one part of\n",
      "Start: 1266.24, End: 1270.72, Text:  the world, it immediately propagates. So you might not be aware that someone else has discovered it\n",
      "Start: 1270.72, End: 1276.64, Text:  and independently discovered this algorithm. That's what was happening at that time. And around 1986,\n",
      "Start: 1277.6000000000001, End: 1286.32, Text:  Riemelhardt and others, including Jeffrey Hinton, popularized in this in the context of neural networks\n",
      "Start: 1286.32, End: 1292.8, Text:  and they showed that this bad propagation algorithm can be used for training neural networks.\n",
      "Start: 1292.8, End: 1298.6399999999999, Text:  And this was an important breakthrough because even to this day, most modern deep neural networks\n",
      "Start: 1298.6399999999999, End: 1306.0, Text:  are trained using the bad propagation algorithm. There was another important and interesting\n",
      "Start: 1306.0, End: 1312.56, Text:  fact is this bad propagation within it, right? Or at the heart of it, there's also gradient descent,\n",
      "Start: 1313.28, End: 1318.72, Text:  which was much older, almost one century, one and a half century before back propagation.\n",
      "Start: 1319.28, End: 1326.56, Text:  And this was discovered or proposed by Kashi, and for a very different purpose. He was trying to use\n",
      "Start: 1326.56, End: 1332.3999999999999, Text:  gradient descent to compute the orbit of heavenly bodies. There's a lot of interest in astronomy\n",
      "Start: 1332.3999999999999, End: 1337.76, Text:  at that time and he was trying to look at what is the orbit of heavenly bodies. And in that context,\n",
      "Start: 1337.76, End: 1344.4, Text:  he had discovered gradient descent. So again, whatever benefits we are enjoying today,\n",
      "Start: 1344.4, End: 1350.4, Text:  they come through the work of many great scientists over centuries in different fields. And that's\n",
      "Start: 1350.4, End: 1358.32, Text:  where that has helped us reach where we are today, very unexpected ways. So while we were still in\n",
      "Start: 1358.32, End: 1365.92, Text:  this winter period, again this 1989, what came up is this universal approximation theorem,\n",
      "Start: 1365.92, End: 1369.76, Text:  which is again something that will come up in the course, right? And what this said, again,\n",
      "Start: 1369.76, End: 1376.0, Text:  to repeat what I said earlier, that if you have a function which takes certain x as input and gives\n",
      "Start: 1376.0, End: 1381.52, Text:  you y. And in real world, you don't know what this f is, right? So in real world, if I want to say,\n",
      "Start: 1381.6, End: 1399.2, Text:  what is my decision? In here, well examples, suppose f is the function that I'm using to decide\n",
      "Start: 1399.2, End: 1404.8, Text:  how to hire people or how to predict the life expectancy of a person. I don't know what this\n",
      "Start: 1404.8, End: 1409.52, Text:  f is and that is not really known. I just know it depends on certain factors, right? But and what I\n",
      "Start: 1409.52, End: 1415.04, Text:  have is several examples of these inputs and outputs that I know a person who had a certain\n",
      "Start: 1415.6, End: 1420.24, Text:  blood pressure level, cholesterol level and so on sugar level. And then I know how long that\n",
      "Start: 1420.24, End: 1426.08, Text:  person lived and so on, right? So I have many such examples. Now what this theorem said is that\n",
      "Start: 1426.8, End: 1431.92, Text:  you could come up with a multi-layered network of neurons, right? Not unlike what\n",
      "Start: 1431.92, End: 1436.72, Text:  Pappert and Minskia said that a single neuron cannot do it. They said that if you have a multi-layered\n",
      "Start: 1436.72, End: 1443.44, Text:  network of neurons, right? Then you could take an x, given many such examples, you could learn a\n",
      "Start: 1443.44, End: 1450.96, Text:  model such that now if you feed an x to it, the y that it's predicts would be very close to f of x,\n",
      "Start: 1450.96, End: 1455.52, Text:  which is the true value of the y that you would have got if you knew what that function is, right?\n",
      "Start: 1455.52, End: 1460.72, Text:  So what it means is that what I'm trying to show in this diagram is this orange curve that you see\n",
      "Start: 1460.8, End: 1472.08, Text:  here, right? Okay, some of the pen is behaving a bit strange. Yeah, the orange curve that you see\n",
      "Start: 1472.08, End: 1477.52, Text:  here, suppose this is what my actual f is and I don't know that, right? And now I'm trying to\n",
      "Start: 1477.52, End: 1483.6000000000001, Text:  approximate it and those I'm doing that approximation with the help of these rectangular bars that\n",
      "Start: 1483.6000000000001, End: 1489.84, Text:  you see, right? And what this was, this theorem said is that if you have a very deep neural network or\n",
      "Start: 1489.84, End: 1493.52, Text:  a multi-layered, in fact, it said even if you have a one-layered network with the large number of\n",
      "Start: 1493.52, End: 1499.6, Text:  neurons, then you can approximate this very, very well, right? And that's what we want to do. We had\n",
      "Start: 1502.32, End: 1514.8, Text:  the two function, which we did not know. All we knew was several instances of x1 and y1 x2 y2.\n",
      "Start: 1514.8, End: 1518.9599999999998, Text:  What this theorem says is that if you have many such instances, you could come up with a neural\n",
      "Start: 1518.96, End: 1525.04, Text:  network, right? And that those rectangular bars are in some sense the output of the neural network\n",
      "Start: 1525.68, End: 1532.56, Text:  such that that output would be very close to the real output, right? And the more neurons you add,\n",
      "Start: 1532.56, End: 1537.2, Text:  the better your approximation would be. If you had fewer of neurons, your approximation would be poor,\n",
      "Start: 1537.2, End: 1542.16, Text:  like you see in this case, but the more neurons you add, it will be better, right? This theorem\n",
      "Start: 1542.16, End: 1546.72, Text:  an illustrative proof of it is something that we'll see, but this was a real breakthrough, right?\n",
      "Start: 1546.72, End: 1553.68, Text:  Because now it has almost the reverse effect of what we had for the proof by Pepper and Minsky,\n",
      "Start: 1553.68, End: 1558.64, Text:  it said that even for simple functions, a single neuron does not work. Now, what this is saying is that\n",
      "Start: 1559.1200000000001, End: 1565.68, Text:  for any arbitrary complex function, not even Boolean functions, any arbitrary function that you have,\n",
      "Start: 1565.68, End: 1570.72, Text:  no longer what the function looks like, you can always come up with a neural network, which will be\n",
      "Start: 1570.88, End: 1576.0, Text:  able to approximate that function to any desired degree of precision, right? And that desired degree of\n",
      "Start: 1576.0, End: 1580.8, Text:  precision is controlled by the number of neurons that you have. I fewer neurons, my approximation\n",
      "Start: 1580.8, End: 1585.1200000000001, Text:  would be very bad, but if I keep adding neurons, my approximation would become better and better,\n",
      "Start: 1585.1200000000001, End: 1592.16, Text:  right? So this is a real breakthrough that was there. And after this, of course, nothing changed,\n",
      "Start: 1592.16, End: 1597.52, Text:  right? But for nothing changed much in the sense that people realize, okay, there is a lot of power\n",
      "Start: 1597.52, End: 1605.92, Text:  in deep neural networks. But for the next 20 years or so, or maybe 17, 18 years, on the back of\n",
      "Start: 1605.92, End: 1610.24, Text:  these two discoveries, one is back propagation, which allows you to train deep neural networks.\n",
      "Start: 1610.24, End: 1614.16, Text:  And the other is the universal approximation theorem, which says that there is value in training deep\n",
      "Start: 1614.16, End: 1620.32, Text:  neural networks, because then you can approximate arbitrary real world functions. People try to apply\n",
      "Start: 1620.32, End: 1625.2, Text:  these ideas, right, to real world problems. But what they notice is that training a multilayer\n",
      "Start: 1625.2, End: 1630.72, Text:  network of neurons using back propagation is not very stable. And it often does not lead to\n",
      "Start: 1630.72, End: 1635.6000000000001, Text:  conversion. So while in theory, you can use back propagation, while in theory, you can approximate\n",
      "Start: 1635.6000000000001, End: 1639.68, Text:  any function. But in practice, when you're trying to train this really deep neural networks,\n",
      "Start: 1639.68, End: 1646.24, Text:  it's not working, right? So in the next few years from 1989 to not few as almost two decades,\n",
      "Start: 1647.44, End: 1652.48, Text:  much practical progress did not happen in terms of deep learning, right? People knew these two things,\n",
      "Start: 1652.48, End: 1656.64, Text:  but they were not really able to make them work. In most cases, there were of course still a lot of\n",
      "Start: 1656.64, End: 1661.3600000000001, Text:  progress happened on convolution neural networks, which you will see soon, right? So that's where we were.\n",
      "Start: 1661.3600000000001, End: 1665.84, Text:  So we started with the spring, where there was a lot of hype and enthusiasm around AI,\n",
      "Start: 1666.4, End: 1671.2, Text:  then things collapsed, and then things kind of stabilized. Okay, let's not completely ignore it.\n",
      "Start: 1671.2, End: 1675.3600000000001, Text:  Let's keep making some progress and see if you can actually use back propagation to train this deep\n",
      "Start: 1675.36, End: 1677.36, Text:  neural networks, right?\n"
     ]
    }
   ],
   "source": [
    "%pip install yt-dlp pydub moviepy whisper gradio\n",
    "\n",
    "import yt_dlp as youtube_dl\n",
    "from pydub import AudioSegment\n",
    "import os\n",
    "import whisper\n",
    "import gradio as gr\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "def download_video_and_extract_audio(video_url):\n",
    "    # Download the video\n",
    "    ydl_opts = {\n",
    "        'format': 'best',\n",
    "        'outtmpl': 'downloaded_video.%(ext)s',\n",
    "    }\n",
    "    with youtube_dl.YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([video_url])\n",
    "    \n",
    "    # Find the downloaded video file\n",
    "    video_path = 'downloaded_video.mp4'\n",
    "    \n",
    "    # Extract the audio using moviepy\n",
    "    video = VideoFileClip(video_path)\n",
    "    audio_path = os.path.splitext(video_path)[0] + '.mp3'\n",
    "    video.audio.write_audiofile(audio_path)\n",
    "    \n",
    "    # Clean up\n",
    "    video.close()\n",
    "    os.remove(video_path)\n",
    "    \n",
    "    print(f\"Audio has been saved to {audio_path}\")\n",
    "    return audio_path\n",
    "\n",
    "def transcribe_audio_with_timestamps(audio_path):\n",
    "    # Load the whisper model\n",
    "    model = whisper.load_model(\"base\")\n",
    "    \n",
    "    # Transcribe the audio with timestamps\n",
    "    result = model.transcribe(audio_path, verbose=True)\n",
    "    \n",
    "    # Print the transcription with timestamps\n",
    "    for segment in result[\"segments\"]:\n",
    "        print(f\"Start: {segment['start']}, End: {segment['end']}, Text: {segment['text']}\")\n",
    "    \n",
    "    return result[\"segments\"]\n",
    "\n",
    "def extract_audio_segments(audio_path, segments):\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    audio_segments = []\n",
    "    \n",
    "    for segment in segments:\n",
    "        start_ms = segment['start'] * 1000  # Convert to milliseconds\n",
    "        end_ms = segment['end'] * 1000  # Convert to milliseconds\n",
    "        audio_segment = audio[start_ms:end_ms]\n",
    "        audio_segments.append({\n",
    "            \"start\": segment['start'],\n",
    "            \"end\": segment['end'],\n",
    "            \"text\": segment['text'],\n",
    "            \"audio\": audio_segment\n",
    "        })\n",
    "    \n",
    "    return audio_segments\n",
    "\n",
    "def chunk_segments(segments, max_length=15.0):\n",
    "    chunked_segments = []\n",
    "    chunk_id = 1\n",
    "    \n",
    "    for segment in segments:\n",
    "        start_time = segment[\"start\"]\n",
    "        end_time = segment[\"end\"]\n",
    "        text = segment[\"text\"]\n",
    "        audio = segment[\"audio\"]\n",
    "        \n",
    "        duration = end_time - start_time\n",
    "        if duration <= max_length:\n",
    "            chunked_segments.append({\n",
    "                \"chunk_id\": chunk_id,\n",
    "                \"chunk_length\": duration,\n",
    "                \"text\": text,\n",
    "                \"start_time\": start_time,\n",
    "                \"end_time\": end_time\n",
    "            })\n",
    "            chunk_id += 1\n",
    "        else:\n",
    "            # Split the segment into smaller chunks\n",
    "            num_chunks = int(duration // max_length) + 1\n",
    "            chunk_duration = duration / num_chunks\n",
    "            for i in range(num_chunks):\n",
    "                chunk_start_time = start_time + i * chunk_duration\n",
    "                chunk_end_time = min(start_time + (i + 1) * chunk_duration, end_time)\n",
    "                chunk_text = text  # This can be improved by splitting the text accordingly\n",
    "                chunk_audio = audio[i * chunk_duration * 1000:(i + 1) * chunk_duration * 1000]\n",
    "                \n",
    "                chunked_segments.append({\n",
    "                    \"chunk_id\": chunk_id,\n",
    "                    \"chunk_length\": chunk_end_time - chunk_start_time,\n",
    "                    \"text\": chunk_text,\n",
    "                    \"start_time\": chunk_start_time,\n",
    "                    \"end_time\": chunk_end_time\n",
    "                })\n",
    "                chunk_id += 1\n",
    "    \n",
    "    return chunked_segments\n",
    "\n",
    "def process_video(youtube_url):\n",
    "    audio_path = download_video_and_extract_audio(youtube_url)\n",
    "    segments = transcribe_audio_with_timestamps(audio_path)\n",
    "    audio_segments = extract_audio_segments(audio_path, segments)\n",
    "    chunked_segments = chunk_segments(audio_segments)\n",
    "    \n",
    "    return chunked_segments\n",
    "\n",
    "iface = gr.Interface(\n",
    "    fn=process_video,\n",
    "    inputs=\"text\",\n",
    "    outputs=\"json\",\n",
    "    title=\"YouTube Video Semantic Chunking\",\n",
    "    description=\"Enter a YouTube video URL to extract and transcribe audio into semantic chunks.\"\n",
    ")\n",
    "\n",
    "iface.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
